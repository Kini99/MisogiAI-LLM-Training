# Reward Modeling Project

This project focuses on training a reward model to evaluate the quality of answers generated by a language model.

## Project Structure

- `answers.csv`: Contains prompts, generated answers, and their manual rankings.
- `reward_model/`: Directory where the trained reward model is saved.
- `analyse.ipynb`: Jupyter notebook for generating answers and evaluating the reward model.
- `train.py`: Script to train the reward model.
- `summary.md`: A summary of the project and its findings.
- `requirements.txt`: Python dependencies for this project.
- `README.md`: This file.

## Steps

1.  **Generate Answers**: Use the `analyse.ipynb` notebook to generate answers for your chosen prompts.
2.  **Rank Answers**: Manually rank the generated answers in `answers.csv`. The ranking should be from 1 (best) to 4 (worst).
3.  **Train Reward Model**: Run `python train.py` to train the reward model on your ranked answers.
4.  **Evaluate**: Use the `analyse.ipynb` notebook to evaluate the trained reward model on a new set of answers.
5.  **Summarize**: Document your findings in `summary.md`. 